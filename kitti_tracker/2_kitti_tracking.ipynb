{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itberrios/CV_tracking/blob/main/kitti_tracker/2_kitti_tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRjlA-8T-pOQ"
      },
      "source": [
        "# **KITTI Tracking**\n",
        "\n",
        "In this tutorial we will learn how to track objects in 3D on the KITTI dataset. We will build off of our object dector from part 1 and use each obejct detection to update the tracks.\n",
        "\n",
        "For more information a readme for the KITTI data can be found [here](https://github.com/yanii/kitti-pcl/blob/master/KITTI_README.TXT), and a paper that details the data collection and coordinate systems can be found [here](http://www.cvlibs.net/publications/Geiger2013IJRR.pdf). \n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the data"
      ],
      "metadata": {
        "id": "b8BfTqJ7_BXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_10_03_drive_0047/2011_10_03_drive_0047_sync.zip"
      ],
      "metadata": {
        "id": "K69AK4e7_FOl",
        "outputId": "651b6267-a956-47eb-8a91-1086c01fc367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-22 11:48:55--  https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_10_03_drive_0047/2011_10_03_drive_0047_sync.zip\n",
            "Resolving s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)... 52.219.171.13\n",
            "Connecting to s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)|52.219.171.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3103291675 (2.9G) [application/zip]\n",
            "Saving to: â€˜2011_10_03_drive_0047_sync.zipâ€™\n",
            "\n",
            "2011_10_03_drive_00 100%[===================>]   2.89G  28.8MB/s    in 1m 43s  \n",
            "\n",
            "2022-09-22 11:50:39 (28.6 MB/s) - â€˜2011_10_03_drive_0047_sync.zipâ€™ saved [3103291675/3103291675]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_10_03_calib.zip"
      ],
      "metadata": {
        "id": "CC3a9bNg_C2S",
        "outputId": "297b344c-75e6-44be-85b6-cf9d489e8324",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-22 11:50:39--  https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_10_03_calib.zip\n",
            "Resolving s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)... 52.219.46.23\n",
            "Connecting to s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)|52.219.46.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4075 (4.0K) [application/zip]\n",
            "Saving to: â€˜2011_10_03_calib.zipâ€™\n",
            "\n",
            "2011_10_03_calib.zi 100%[===================>]   3.98K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-22 11:50:40 (192 MB/s) - â€˜2011_10_03_calib.zipâ€™ saved [4075/4075]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jar xf 2011_10_03_drive_0047_sync.zip\n",
        "!jar xf 2011_10_03_calib.zip"
      ],
      "metadata": {
        "id": "FnayIl6N_HrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Library Import"
      ],
      "metadata": {
        "id": "lXqKyrfp_Jh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 10)"
      ],
      "metadata": {
        "id": "lgM4JrRc_I-h"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Utility functions"
      ],
      "metadata": {
        "id": "lMDnx_XP_ON7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/itberrios/CV_tracking/raw/main/kitti_tracker/kitti_utils.py\n",
        "from kitti_utils import *"
      ],
      "metadata": {
        "id": "gs5psD0dRRJN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget https://github.com/itberrios/CV_tracking/raw/main/kitti_tracker/kitti_detection_utils.py\n",
        "from kitti_detection_utils import *"
      ],
      "metadata": {
        "id": "oK9MoM5o_MNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Data Paths"
      ],
      "metadata": {
        "id": "OwE2dxKP_WAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = r'2011_10_03/2011_10_03_drive_0047_sync'\n",
        "\n",
        "# get RGB camera data\n",
        "left_image_paths = sorted(glob(os.path.join(DATA_PATH, 'image_02/data/*.png')))\n",
        "right_image_paths = sorted(glob(os.path.join(DATA_PATH, 'image_03/data/*.png')))\n",
        "\n",
        "# get LiDAR data\n",
        "bin_paths = sorted(glob(os.path.join(DATA_PATH, 'velodyne_points/data/*.bin')))\n",
        "\n",
        "# get GPS/IMU data\n",
        "oxts_paths = sorted(glob(os.path.join(DATA_PATH, r'oxts/data**/*.txt')))\n",
        "\n",
        "print(f\"Number of left images: {len(left_image_paths)}\")\n",
        "print(f\"Number of right images: {len(right_image_paths)}\")\n",
        "print(f\"Number of LiDAR point clouds: {len(bin_paths)}\")\n",
        "print(f\"Number of GPS/IMU frames: {len(oxts_paths)}\")"
      ],
      "metadata": {
        "id": "XDH7Nhn5_Vdd",
        "outputId": "0a908f66-f484-4425-b4f6-e9e47a2b8b69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of left images: 837\n",
            "Number of right images: 837\n",
            "Number of LiDAR point clouds: 837\n",
            "Number of GPS/IMU frames: 837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Camera Transformation Matrices"
      ],
      "metadata": {
        "id": "EYRASHTc_a-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('2011_10_03/calib_cam_to_cam.txt','r') as f:\n",
        "    calib = f.readlines()\n",
        "\n",
        "# get projection matrices (rectified left camera --> left camera (u,v,z))\n",
        "P_rect2_cam2 = np.array([float(x) for x in calib[25].strip().split(' ')[1:]]).reshape((3,4))\n",
        "\n",
        "\n",
        "# get rectified rotation matrices (left camera --> rectified left camera)\n",
        "R_ref0_rect2 = np.array([float(x) for x in calib[24].strip().split(' ')[1:]]).reshape((3, 3,))\n",
        "\n",
        "# add (0,0,0) translation and convert to homogeneous coordinates\n",
        "R_ref0_rect2 = np.insert(R_ref0_rect2, 3, values=[0,0,0], axis=0)\n",
        "R_ref0_rect2 = np.insert(R_ref0_rect2, 3, values=[0,0,0,1], axis=1)\n",
        "\n",
        "\n",
        "# get rigid transformation from Camera 0 (ref) to Camera 2\n",
        "R_2 = np.array([float(x) for x in calib[21].strip().split(' ')[1:]]).reshape((3,3))\n",
        "t_2 = np.array([float(x) for x in calib[22].strip().split(' ')[1:]]).reshape((3,1))\n",
        "\n",
        "# get cam0 to cam2 rigid body transformation in homogeneous coordinates\n",
        "T_ref0_ref2 = np.insert(np.hstack((R_2, t_2)), 3, values=[0,0,0,1], axis=0)"
      ],
      "metadata": {
        "id": "FxmHiWjH_ZqT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get LiDAR and IMU Transformation matrices"
      ],
      "metadata": {
        "id": "Ymr3IGeH_kuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T_velo_ref0 = get_rigid_transformation(r'2011_10_03/calib_velo_to_cam.txt')\n",
        "T_imu_velo = get_rigid_transformation(r'2011_10_03/calib_imu_to_velo.txt')"
      ],
      "metadata": {
        "id": "cRlNyw53_j5t"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get LiDAR â¬Œ Camera2 Rotation matrices\n",
        "\n",
        "LiDAR &rarr; Cam Ref 0 &rarr; Cam Ref 2 &rarr; Rectified 2 &rarr; Camera 2"
      ],
      "metadata": {
        "id": "Vz-T9MBnAjsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transform from velo (LiDAR) to left color camera (shape 3x4)\n",
        "T_velo_cam2 = P_rect2_cam2 @ R_ref0_rect2 @ T_ref0_ref2 @ T_velo_ref0 \n",
        "\n",
        "# homogeneous transform from left color camera to velo (LiDAR) (shape: 4x4)\n",
        "T_cam2_velo = np.linalg.inv(np.insert(T_velo_cam2, 3, values=[0,0,0,1], axis=0)) "
      ],
      "metadata": {
        "id": "ba_C6VjVAX1i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get IMU â¬Œ Camera2 Rotation matrices\n",
        "\n",
        "IMU &rarr; LiDAR &rarr; Cam Ref 0 &rarr; Cam Ref 2 &rarr; Rectified 2 &rarr; Camera 2"
      ],
      "metadata": {
        "id": "nJcbv-AxBJxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transform from IMU to left color camera (shape 3x4)\n",
        "T_imu_cam2 = T_velo_cam2 @ T_imu_velo\n",
        "\n",
        "# homogeneous transform from left color camera to IMU (shape: 4x4)\n",
        "T_cam2_imu = np.linalg.inv(np.insert(T_imu_cam2, 3, values=[0,0,0,1], axis=0)) "
      ],
      "metadata": {
        "id": "che3QAEjAhkZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Get Object Detection pipeline**"
      ],
      "metadata": {
        "id": "1ptISKMrBxP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "id": "uagV1pAQAi0N",
        "outputId": "fa8358dd-938c-46a8-8a67-253e4e91813d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r yolov5/requirements.txt  #Install whatever is needed"
      ],
      "metadata": {
        "id": "H36aVY1HB5rk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5m, yolov5l, yolov5x, custom"
      ],
      "metadata": {
        "id": "bzz2r4qgB7SL",
        "outputId": "f882a177-7698-49ce-8748-4f5a18e687fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2022-9-22 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set confidence and IOU thresholds\n",
        "model.conf = 0.25  # confidence threshold (0-1), default: 0.25\n",
        "model.iou = 0.25  # NMS IoU threshold (0-1), default: 0.45"
      ],
      "metadata": {
        "id": "eX4ENFYUB9aA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Set up tracking pipeline**\n",
        "\n",
        "The tracking will be a 3D real world extension of the [SORT algorithm](https://arxiv.org/pdf/1602.00763.pdf). Instead of tracking bounding box location and aspect, we will simple track the (x, y) locations of each detected object. For this was we will neglect the z-axis. In our Kalman Filter we will use a constanct velocity model with a random accleration assumption.\n",
        "\n",
        "The tracking pipeline will use the object detection methods from part 1 as a backbone. The L2 distance between object (x,y,z) centers will be used as a cost. The Hungarian Algorithm (linear_sum_assignemnt in Python) will be used to match old tracks with new updates and determine if tracks are not updated."
      ],
      "metadata": {
        "id": "b3lqvIn4Gq9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "# tracker params\n",
        "MIN_HIT_STREAK = 1\n",
        "MAX_UNMATCHED_AGE = 2\n",
        "\n",
        "# helper functions\n",
        "def total_cost(center1, center2):\n",
        "    ''' Return L2 distance between object centers '''\n",
        "    return np.linalg.norm(center1 - center2)\n",
        "\n",
        "\n",
        "def associate(old_centers, new_centers, dist_thresh=1):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        old_centers - former center locations (at time 0)\n",
        "        new_centers - new center locations (at time 1)\n",
        "        dist_thresh - distance threshold to declare tracks matched or unmatched\n",
        "    Outputs:\n",
        "       matches - Matched tracks\n",
        "       unmatched_detections - Unmatched Detections\n",
        "       unmatched_trackers - Unmatched Tracks\n",
        "\n",
        "    \"\"\"\n",
        "    if (len(new_centers) == 0) and (len(old_centers) == 0):\n",
        "        return [], [], []\n",
        "    elif(len(old_centers)==0):\n",
        "        return [], new_centers, []\n",
        "    elif(len(new_centers)==0):\n",
        "        return [], [], old_centers\n",
        "\n",
        "    # distances will store L2 distances between object centers\n",
        "    distances = np.zeros((len(old_centers),len(new_centers)),dtype=np.float32)\n",
        "\n",
        "    # Go through centers and store the L2 distances between all of them\n",
        "    for i,old_cntr in enumerate(old_centers):\n",
        "        for j,new_cntr in enumerate(new_centers):\n",
        "            distances[i][j] = total_cost(old_cntr, new_cntr)\n",
        "\n",
        "    # TEMP\n",
        "    print(distances)\n",
        "\n",
        "    # Hungarian Algorithm (with L2 distance metric as the cost)\n",
        "    row_ind, col_ind = linear_sum_assignment(distances)\n",
        "    hungarian_matrix = np.array(list(zip(row_ind, col_ind)))\n",
        "\n",
        "    # Create new unmatched lists for old and new boxes\n",
        "    matches, unmatched_detections, unmatched_tracks = [], [], []\n",
        "\n",
        "    # Go through the Hungarian Matrix, if matched element has dist <= threshold (0.3), add it to the unmatched \n",
        "    # Else: add the match    \n",
        "    for h in hungarian_matrix:\n",
        "        if(distances[h[0],h[1]] > dist_thresh):\n",
        "            unmatched_tracks.append(old_centers[h[0]])\n",
        "            unmatched_detections.append(new_centers[h[1]])\n",
        "        else:\n",
        "            matches.append(h.reshape(1,2))\n",
        "\n",
        "    if(len(matches)==0):\n",
        "        matches = np.empty((0,2), dtype=int)\n",
        "    else:\n",
        "        matches = np.concatenate(matches, axis=0)\n",
        "\n",
        "    # Go through old centers, if no matched detection, add it to the unmatched_old_centers\n",
        "    for t, trk in enumerate(old_centers):\n",
        "        if(t not in hungarian_matrix[:,0]):\n",
        "            unmatched_tracks.append(trk)\n",
        "\n",
        "    # Go through new boxes, if no matched tracking, add it to the unmatched_new_centers\n",
        "    for d, det in enumerate(new_centers):\n",
        "        if(d not in hungarian_matrix[:,1]):\n",
        "            unmatched_detections.append(det)\n",
        "\n",
        "    return matches, unmatched_detections, unmatched_tracks\n",
        "  "
      ],
      "metadata": {
        "id": "X5Wpx6tGB-6Q"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test track pipeline"
      ],
      "metadata": {
        "id": "zzC9xhsCLPdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index1 = 20\n",
        "index2 = 21\n",
        "\n",
        "left_image_1 = cv2.cvtColor(cv2.imread(left_image_paths[index1]), cv2.COLOR_BGR2RGB)\n",
        "bin_path_1 = bin_paths[index1]\n",
        "\n",
        "left_image_2 = cv2.cvtColor(cv2.imread(left_image_paths[index2]), cv2.COLOR_BGR2RGB)\n",
        "bin_path_2 = bin_paths[index2]\n"
      ],
      "metadata": {
        "id": "od43lebwGg4G"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imu_xyz_1 = get_imu_xyz(left_image_1, bin_path_1, model, T_velo_cam2, T_cam2_imu)"
      ],
      "metadata": {
        "id": "xkzA6C_ULRNF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imu_xyz_2 = get_imu_xyz(left_image_2, bin_path_2, model, T_velo_cam2, T_cam2_imu)"
      ],
      "metadata": {
        "id": "OMNNmyA5SDn7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imu_xyz_1"
      ],
      "metadata": {
        "id": "2nbwM4-SSGsE",
        "outputId": "77767e1f-9b6e-41a8-f797-c133fbc47e99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[     11.911,      -2.722,    -0.16906],\n",
              "       [     15.574,       7.346,    -0.16672],\n",
              "       [     11.089,      3.1335,    -0.13419],\n",
              "       [     23.339,     -2.8507,   -0.010265],\n",
              "       [     22.384,      3.5784,   -0.070647],\n",
              "       [     46.072,      0.4007,     0.27154],\n",
              "       [     29.946,      3.2677,   -0.044347],\n",
              "       [     56.769,     -2.0642,     0.13642],\n",
              "       [     13.094,      2.8895,     0.36942],\n",
              "       [     52.366,      4.0757,     0.11331],\n",
              "       [     45.877,     -3.0317,   0.0097941],\n",
              "       [     23.318,      2.8036,   -0.096056]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imu_xyz_2"
      ],
      "metadata": {
        "id": "pVr5qwC1SH_r",
        "outputId": "ee590a5f-cbc4-4a5a-811e-4063d0297129",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[     15.315,       7.299,     -0.1505],\n",
              "       [     11.965,      -2.751,    -0.10473],\n",
              "       [     11.027,      3.1306,    -0.12802],\n",
              "       [      23.49,     -2.8317,   -0.016854],\n",
              "       [     22.356,      3.6084,   -0.070034],\n",
              "       [     29.881,      3.2596,   -0.042096],\n",
              "       [     57.115,     -1.8578,    -0.26439],\n",
              "       [     46.409,     0.33389,     0.26685],\n",
              "       [     52.351,      3.9927,     0.11557],\n",
              "       [     31.399,      7.6322,    -0.18401],\n",
              "       [     46.348,     -3.0605, -0.00073378]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matches, unmatched_detections, unmatched_tracks = associate(imu_xyz_1, imu_xyz_2, dist_thresh=1)"
      ],
      "metadata": {
        "id": "oJ9FmUZISI4N",
        "outputId": "a87894a3-d24b-477e-ab3b-84c38a549ffa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[     10.583    0.088346      5.9191       11.58      12.214       18.94      45.212      34.635      40.994      22.067      34.439]\n",
            " [    0.26366      10.723      6.2004      12.895      7.7444       14.88      42.548      31.625      36.931      15.827      32.487]\n",
            " [     5.9338      5.9494    0.062362      13.761      11.277      18.793      46.296      35.433      41.272      20.802      35.799]\n",
            " [     12.939      11.375      13.688     0.15231      6.5337      8.9521      33.791      23.291      29.809      13.224       23.01]\n",
            " [     7.9888      12.191      11.366       6.505    0.041049      7.5041      35.154      24.246      29.971      9.8849      24.867]\n",
            " [     31.524      34.255      35.153      22.814      23.935      16.444      11.284     0.34363      7.2355      16.365      3.4829]\n",
            " [     15.177      18.962       18.92      8.8818       7.598     0.06552      27.649      16.725      22.417       4.602       17.58]\n",
            " [     42.499       44.81      46.036      33.288      34.878       27.41      0.5683      10.634      7.4968      27.162      10.469]\n",
            " [     4.9644      5.7721      2.1398      11.872      9.2998      16.796       44.28      33.413      39.273      18.917      33.784]\n",
            " [     37.192      40.975       41.35      29.691      30.014        22.5      7.6092      7.0363    0.084351      21.269      9.3356]\n",
            " [     32.261      33.914      35.391      22.388      24.441      17.189      11.302      3.4171      9.5533      17.983     0.47199]\n",
            " [     9.1798       12.64      12.296      5.6385      1.2549      6.5788      34.117      23.225      29.058      9.4134      23.765]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matches"
      ],
      "metadata": {
        "id": "hEgNcuESSfwo",
        "outputId": "18af7ade-158b-4576-e453-4992aa2ee976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1],\n",
              "       [ 1,  0],\n",
              "       [ 2,  2],\n",
              "       [ 3,  3],\n",
              "       [ 4,  4],\n",
              "       [ 5,  7],\n",
              "       [ 6,  5],\n",
              "       [ 7,  6],\n",
              "       [ 9,  8],\n",
              "       [10, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unmatched_detections"
      ],
      "metadata": {
        "id": "0_h32f9ISgXg",
        "outputId": "0bc7fc04-59b9-40a0-fcf6-c17b4f505c88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([     31.399,      7.6322,    -0.18401])]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unmatched_tracks"
      ],
      "metadata": {
        "id": "Xfant_T1SrQt",
        "outputId": "055c8fd4-c838-4304-da95-7fb6ca7a3e73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([     23.318,      2.8036,   -0.096056]),\n",
              " array([     13.094,      2.8895,     0.36942])]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJzdVYPDTsUb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}